# build image command: apptainer build image.sif my_recipe.def
Bootstrap: docker
#From: continuumio/miniconda3
From: continuumio/miniconda3:latest


%setup
    mkdir ${APPTAINER_ROOTFS}/requirement

%files
    ../src .
    ../requirements.txt requirement


%post
    # Update conda
    conda update -n base -c defaults conda
    
    # Install Python (if not already included in your base image)
    # conda install -y python=3.8
    conda install -y python=3.10
    

    # Install the CUDA Toolkit and specific PyTorch with CUDA support
    #conda install -c nvidia cuda-toolkit=12.1


    # Working version: torch version: 2.1.2+cu121, dgl version: 2.1.0+cu121
    # local: python3.8 -m pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html
    # local: python3.8 -m pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html

    #pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
    pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121 #official

    #pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html
    pip install  dgl -f https://data.dgl.ai/wheels/torch-2.1/cu121/repo.html #official
    #pip install  dgl==2.1.0 -f https://data.dgl.ai/wheels/cu121/repo.html
    pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html


    # Any additional setup can go here
    pip install -r requirement/requirements.txt

    pip install mlflow torch
    pip install lightning
    pip install torchmetrics
    pip install deepspeed
    pip install colorama




%environment
    export LC_ALL=C.UTF-8
    export LANG=C.UTF-8
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export PATH=/opt/conda/bin:$PATH

    #libcusparse.so.12
    export LD_LIBRARY_PATH=/apps/.skylake/Alvis/software/NVHPC/23.7-CUDA-12.1.1/Linux_x86_64/23.7/REDIST/math_libs/12.2/targets/x86_64-linux/lib:$LD_LIBRARY_PATH
    #libnvJitLink.so.12
    export LD_LIBRARY_PATH=/apps/.skylake/Alvis/software/NVHPC/23.7-CUDA-12.1.1/Linux_x86_64/23.7/cuda/12.2/targets/x86_64-linux/lib:$LD_LIBRARY_PATH
    #export LD_LIBRARY_PATH=/apps/Common/software/CUDA/12.1.1/targets/x86_64-linux/lib:$LD_LIBRARY_PATH

    
%runscript
    exec python "$@"

